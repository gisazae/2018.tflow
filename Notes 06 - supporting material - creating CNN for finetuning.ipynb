{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import tflearn, psutil, gc\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free mem 1.06 GB\n"
     ]
    }
   ],
   "source": [
    "from rlx.utils import humanbytes\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will be creating the same CNN  for binary classification of MNIST (even/odd)\n",
    "\n",
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "free mem 783.03 MB\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data import read_data_sets\n",
    "mnist = read_data_sets(\"/tmp/MNIST_data/\", one_hot=True, reshape=False, validation_size=0)\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print mnist.train.images.shape\n",
    "print mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = {0: \"even\", 1: \"odd\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images used for training and test\n",
    "n=len(mnist.train.images)\n",
    "\n",
    "cnames = {0: \"even\", 1: \"odd\"}\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "idxs = np.random.permutation(range(len(mnist.train.images)))[:n]\n",
    "train_imgs = mnist.train.images[idxs]\n",
    "train_labels = np.r_[[np.argwhere(i)[0][0] for i in mnist.train.labels[idxs]]]%2\n",
    "train_ohlabs = OneHotEncoder().fit_transform(train_labels.reshape(-1,1)).toarray().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn = n if n<mnist.test.images.shape[0] else mnist.test.images.shape[0]\n",
    "\n",
    "idxs = np.random.permutation(range(len(mnist.test.images)))[:n]\n",
    "test_imgs = mnist.test.images[idxs]\n",
    "test_labels = np.r_[[np.argwhere(i)[0][0] for i in mnist.test.labels[idxs]]]%2\n",
    "test_ohlabs = OneHotEncoder().fit_transform(test_labels.reshape(-1,1)).toarray().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "(60000,) (10000,)\n",
      "(60000, 2) (10000, 2)\n",
      "free mem 602.33 MB\n"
     ]
    }
   ],
   "source": [
    "print train_imgs.shape, test_imgs.shape\n",
    "print train_labels.shape, test_labels.shape\n",
    "print train_ohlabs.shape, test_ohlabs.shape\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free mem 868.86 MB\n"
     ]
    }
   ],
   "source": [
    "del(mnist)\n",
    "gc.collect()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    30508\n",
      "0    29492\n",
      "dtype: int64\n",
      "1    5074\n",
      "0    4926\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print pd.Series(train_labels).value_counts()\n",
    "print pd.Series(test_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use `tflearn` to create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tflearn.models.dnn.DNN'> <class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_ohlabs.shape[1]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "network1 = input_data(shape=[None, 28, 28, 1])\n",
    "network2 = conv_2d(network1, 9, 5, strides=1, activation='relu', name=\"conv1\", padding=\"SAME\")\n",
    "network3 = conv_2d(network2, 18, 4, strides=2, activation='relu', name=\"conv2\", padding=\"SAME\")\n",
    "network4 = fully_connected(network3, 100, activation='relu', name='fc1')\n",
    "network5 = fully_connected(network4, num_classes, activation='softmax', name='fc2')\n",
    "network6 = regression(network5, optimizer=\"adam\",  loss='categorical_crossentropy')\n",
    "\n",
    "model   = tflearn.DNN(network6, tensorboard_verbose=0, tensorboard_dir=\"log\")\n",
    "print type(model), type(network6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free mem 866.43 MB\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and use `tensorboard` to see progress and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name tflearn_cnn_binmnist_2018-01-11_13:15\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tflearn_cnn_binmnist_\" + datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "print \"model name\", model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5999  | total loss: \u001b[1m\u001b[32m0.00416\u001b[0m\u001b[0m | time: 105.788s\n",
      "| Adam | epoch: 010 | loss: 0.00416 - acc: 0.9988 -- iter: 59900/60000\n",
      "Training Step: 6000  | total loss: \u001b[1m\u001b[32m0.00387\u001b[0m\u001b[0m | time: 109.636s\n",
      "| Adam | epoch: 010 | loss: 0.00387 - acc: 0.9989 | val_loss: 0.02676 - val_acc: 0.9933 -- iter: 60000/60000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(train_imgs, train_ohlabs, n_epoch=10,  validation_set=(test_imgs, test_ohlabs), shuffle=True,\n",
    "          show_metric=True, batch_size=100, snapshot_step=100, snapshot_epoch=False, run_id=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13ec2d11d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w1 = model.get_weights(tflearn.get_all_trainable_variable()[0])\n",
    "print w1.shape\n",
    "def display_imgs(w, figsize=(10,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(w.shape[-1]):\n",
    "        plt.subplot(1,w.shape[-1],i+1)\n",
    "        plt.imshow(w[:,:,i], cmap = plt.cm.Greys_r, interpolation=\"none\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(i)\n",
    "\n",
    "display_imgs(w1[:,:,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save weights in h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'conv1/W:0': <tf.Variable 'conv1/W:0' shape=(5, 5, 1, 9) dtype=float32_ref>,\n",
       " u'conv1/b:0': <tf.Variable 'conv1/b:0' shape=(9,) dtype=float32_ref>,\n",
       " u'conv2/W:0': <tf.Variable 'conv2/W:0' shape=(4, 4, 9, 18) dtype=float32_ref>,\n",
       " u'conv2/b:0': <tf.Variable 'conv2/b:0' shape=(18,) dtype=float32_ref>,\n",
       " u'fc1/W:0': <tf.Variable 'fc1/W:0' shape=(3528, 100) dtype=float32_ref>,\n",
       " u'fc1/b:0': <tf.Variable 'fc1/b:0' shape=(100,) dtype=float32_ref>,\n",
       " u'fc2/W:0': <tf.Variable 'fc2/W:0' shape=(100, 2) dtype=float32_ref>,\n",
       " u'fc2/b:0': <tf.Variable 'fc2/b:0' shape=(2,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = {i.name:i for i in tflearn.variables.get_all_trainable_variable()}\n",
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving conv1/W:0 (5, 5, 1, 9)\n",
      "saving conv1/b:0 (9,)\n",
      "saving conv2/W:0 (4, 4, 9, 18)\n",
      "saving conv2/b:0 (18,)\n",
      "saving fc1/W:0 (3528, 100)\n",
      "saving fc1/b:0 (100,)\n",
      "saving fc2/W:0 (100, 2)\n",
      "saving fc2/b:0 (2,)\n",
      "weights saved into pretrained_models/binmnist.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "fname = 'pretrained_models/binmnist.h5'\n",
    "h5f = h5py.File(fname, 'w')\n",
    "for k in np.sort(vars.keys()):\n",
    "    val = model.get_weights(vars[k])\n",
    "    print \"saving\", k, val.shape\n",
    "    h5f.create_dataset(k, data=val)\n",
    "h5f.close()\n",
    "print \"weights saved into\", fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

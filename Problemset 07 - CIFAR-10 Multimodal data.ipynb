{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from rlx.ml import Batches, show_image_mosaic\n",
    "from rlx.utils import humanbytes\n",
    "from time import time\n",
    "import tflearn, psutil, gc\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Load CIFAR-10 and create `info` data\n",
    "\n",
    "### Part A: Load CIFATR10\n",
    "download the dataset from https://www.cs.toronto.edu/~kriz/cifar.html and create a function to return selected batches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar(batches = [1,2,3,4,5]):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "    \n",
    "    return imgs, labels, ohlabs\n",
    "\n",
    "def train_test_split(imgs, labels, ohlabs, train_pct=.8, shuffle=True):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "\n",
    "    return train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** we will use only batch 1**. create variables as in previous problemsets and create additional **INFO** variables with the new information.\n",
    "\n",
    "data shapes must be as follows:\n",
    "\n",
    "        imgs         (10000, 32, 32, 3)\n",
    "        labels       (10000,)\n",
    "        onehot       (10000, 10)\n",
    "        train_imgs   (8000, 32, 32, 3)\n",
    "        train_labels (8000,)\n",
    "        train_ohlabs (8000, 10)\n",
    "        train_info   (8000,)\n",
    "        test_imgs    (2000, 32, 32, 3)\n",
    "        test_labels  (2000,)\n",
    "        test_ohlabs  (2000, 10)\n",
    "        test_info    (2000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels, ohlabs = load_cifar(batches = [1])\n",
    "d = train_test_split(imgs, labels, ohlabs,)\n",
    "train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs = d\n",
    "\n",
    "print \"imgs  \", imgs.shape\n",
    "print \"labels\", labels.shape\n",
    "print \"onehot\", ohlabs.shape\n",
    "print \"train_imgs  \", train_imgs.shape\n",
    "print \"train_labels\", train_labels.shape\n",
    "print \"train_ohlabs\", train_ohlabs.shape\n",
    "print \"test_imgs   \", test_imgs.shape\n",
    "print \"test_labels \", test_labels.shape\n",
    "print \"test_ohlabs \", test_ohlabs.shape\n",
    "gc.collect()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Generate info\n",
    "\n",
    "we will add **ONE NEURON** at the last **fully connected layer** with the following values:\n",
    "\n",
    "- **+1** if the image corresponds to a **LIVING THING**\n",
    "- **-1** otherwise\n",
    "\n",
    "complete the following function to transform the `labels` numpy array passed as argument using this convention, such as\n",
    "\n",
    "    [3, 1, 7, 9] --> [1, -1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labcode= np.r_[[  0    ,   1,     2,      3,     4,      5,      6,      7,       8,      9   ]]\n",
    "cnames = np.r_[[\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"boat\", \"truck\"]]\n",
    "info   = np.r_[[ -1,      -1,     1,      1,     1,      1,      1,      1,       -1,     -1  ]]\n",
    "\n",
    "def get_info(labels):\n",
    "    \n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    labels_info = ...\n",
    "    \n",
    "    return labels_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we create the info variables for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = get_info(train_labels)\n",
    "test_info  = get_info(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Build `tflearn` model\n",
    "\n",
    "use the same network as in the previous problemset **BUT** add an additional input neuron at OUTPUT layer:\n",
    "\n",
    "| layer   | input_size  | output_size | filter_size  | stride | n_filters |activation| var sizes  | params |\n",
    "| ------- |:-----------:|:-----------:|:------------:|:------:|:---------:|:--------:|:--------------:| |\n",
    "| conv1   | 32x32x3     | 32x32x9     | 5x5          |1       | 15        | relu     | W1 = [5,5,3,15]<br/> b = [15]|-|\n",
    "| conv2   | 32x32x15    | 16x16x18    | 5x5          |2       | 18        | relu     | W2 = [5,5,15,18]<br/> b = [18]|-|\n",
    "| conv3   | 16x16x18    | 8x8x20      | 3x3          |2       | 20        | relu     | W2 = [3,3,18,20]<br/> b =[20]|-|\n",
    "| maxpool | 8x8x20      | 4x4x20      |              |        |           |          | | k = 2 |\n",
    "| fc      | 4x4x20      |    100      |              |        |           | relu     | W3 = [320,100]<br/>b=[100]|-|\n",
    "| dropout | 100         |   100       |              |        |           |          | | pkeep = .75 |\n",
    "| output **+ INFO**  | **101**         |   10        |              |        |           | softmax  | W4 = [**101**,10]<br/>b=[10]|-|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TF_graph():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope(\"data\"):\n",
    "        # --------------------------\n",
    "        # YOUR CODE HERE\n",
    "        # --------------------------\n",
    "        X      = ... \n",
    "        X_info = ...\n",
    "        \n",
    "        Y      = ...\n",
    "        network = tf.reshape(X, [-1, 32, 32, 3])\n",
    "    \n",
    "    with tf.name_scope(\"layers\"):\n",
    "        # --------------------------\n",
    "        # YOUR CODE HERE\n",
    "        # --------------------------\n",
    "\n",
    "        num_classes=10\n",
    "        network = ...\n",
    "        network = ...\n",
    "        network = ...\n",
    "        y_hat   = ...\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        # --------------------------\n",
    "        # YOUR CODE HERE\n",
    "        # --------------------------\n",
    "        cross_entropy = ...\n",
    "        loss          = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_pred = tf.equal(tf.argmax(y_hat, 1), tf.argmax(Y, 1))\n",
    "        accuracy     = tf.reduce_mean(tf.cast(correct_pred, tf.float32))    \n",
    "    \n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        # --------------------------\n",
    "        # YOUR CODE HERE\n",
    "        # --------------------------\n",
    "        train_step = ...\n",
    "        \n",
    "    return X, Y, X_info, y_hat, loss, train_step, accuracy\n",
    "\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_info, y_hat, loss, train_step, accuracy = get_TF_graph()\n",
    "vars = {i.name:i for i in tflearn.variables.get_all_trainable_variable()}\n",
    "vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: implement optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn_cifar10_info_\" + datetime.now().strftime(\"%m-%d_%H:%M\")\n",
    "print model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (X, Y, X_info,\n",
    "         X_train, y_train, X_train_info, X_test, y_test, X_test_info,\n",
    "         model_name, loss, train_step, accuracy, \n",
    "         batch_size, n_epochs, log_freq):\n",
    "    \n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "    \n",
    "    return log_train, log_test, model_name\n",
    "\n",
    "def plot_results(log_train, log_test):\n",
    "    k = log_train.rolling(window=10).mean().dropna()\n",
    "    plt.plot(k.time, k.accuracy, color=\"blue\", lw=2, label=\"train\")\n",
    "    plt.plot(log_test.time, log_test.accuracy, color=\"red\",lw=2, label=\"test\")\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1,.5))\n",
    "    plt.plot(log_train.time, log_train.accuracy, alpha=.3, color=\"blue\")\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"elapsed time (secs)\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.axhline(0.5, color=\"black\")\n",
    "    plt.xlim(0,log_train.time.max()+1)\n",
    "    plt.title(\"final train_acc=%.4f, test_acc=%.4f\"%(log_train.accuracy.values[-1], log_test.accuracy.values[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train your model !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_info, y_hat, loss, train_step, accuracy = get_TF_graph()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train, log_test, model_name = fit(X, Y, X_info,\n",
    "                                      train_imgs, train_ohlabs, train_info,\n",
    "                                      test_imgs, test_ohlabs, test_info,\n",
    "                                      \"extended_cnn_mnist\", loss, train_step, accuracy,\n",
    "                                      batch_size=100, n_epochs=15, log_freq=80)\n",
    "\n",
    "plot_results(log_train, log_test)\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: visualize filters, sample misses and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# YOUR CODE HERE\n",
    "# --------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

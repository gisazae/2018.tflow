{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from rlx.ml import Batches, show_image_mosaic\n",
    "from rlx.utils import humanbytes\n",
    "from time import time\n",
    "import tflearn, psutil, gc\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Get CIFAR-10\n",
    "\n",
    "### Part A: Load CIFAR-10\n",
    "download the dataset from https://www.cs.toronto.edu/~kriz/cifar.html and create a function to return selected batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar(batches = [1,2,3,4,5]):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "    \n",
    "    return imgs, labels, ohlabs\n",
    "\n",
    "def train_test_split(imgs, labels, ohlabs, train_pct=.8, shuffle=True):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "\n",
    "    return train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now create the TEST/TRAIN split. ** we will use only batch 1  ** and select randomly **80%** for **TRAIN** and the rest for **TEST**\n",
    "\n",
    "variables names and shapes must be as follows:\n",
    "\n",
    "\n",
    "        VARIABLE NAME   SHAPE\n",
    "        \n",
    "        imgs            (10000, 32, 32, 3)\n",
    "        labels          (10000,)\n",
    "        onehot          (10000, 10)\n",
    "\n",
    "        train_imgs      (8000, 32, 32, 3)\n",
    "        train_labels    (8000,)\n",
    "        train_ohlabs    (8000, 10)\n",
    "\n",
    "        test_imgs       (2000, 32, 32, 3)\n",
    "        test_labels     (2000,)\n",
    "        test_ohlabs     (2000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels, ohlabs = load_cifar(batches = [1])\n",
    "d = train_test_split(imgs, labels, ohlabs,)\n",
    "train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs = d\n",
    "\n",
    "print \"imgs  \", imgs.shape\n",
    "print \"labels\", labels.shape\n",
    "print \"onehot\", ohlabs.shape\n",
    "print \"train_imgs  \", train_imgs.shape\n",
    "print \"train_labels\", train_labels.shape\n",
    "print \"train_ohlabs\", train_ohlabs.shape\n",
    "print \"test_imgs   \", test_imgs.shape\n",
    "print \"test_labels \", test_labels.shape\n",
    "print \"test_ohlabs \", test_ohlabs.shape\n",
    "gc.collect()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: additional channel\n",
    "\n",
    "create a function to add an additional channel to each image with [`skimage.segmentation.quickshift`](http://scikit-image.org/docs/dev/api/skidmage.segmentation.html#skimage.segmentation.quickshift) and params `max_dist=15, ratio=.8`\n",
    "\n",
    "        input shape: (n, x_pixels, y_pixels, 3)\n",
    "        ouput shape: (n, x_pixels, y_pixels, 4)\n",
    "        \n",
    "suggestion: first create the segmented 1 channel images and the use [`np.insert`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.insert.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_channel(imgs):\n",
    "    from skimage import segmentation\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    augmented_imgs ...\n",
    "    return augmented_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now add the channel to train and test imgs. observe the **EXTRA CHANNEL** in their shapes:\n",
    "\n",
    "\n",
    "        VARIABLE NAME   SHAPE\n",
    "\n",
    "        train_imgs      (8000, 32, 32, 4)\n",
    "        train_labels    (8000,)\n",
    "        train_ohlabs    (8000, 10)\n",
    "\n",
    "        test_imgs       (2000, 32, 32, 4)\n",
    "        test_labels     (2000,)\n",
    "        test_ohlabs     (2000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = add_channel(train_imgs)\n",
    "test_imgs  = add_channel(test_imgs)\n",
    "\n",
    "print \"train \", train_imgs.shape\n",
    "print \"test  \", test_imgs.shape\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_mosaic(train_imgs[:,:,:,:3], train_labels, idxs=range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_mosaic(train_imgs[:,:,:,3], train_labels, idxs=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Build `tflearn` model\n",
    "\n",
    "use the same network as in the previous problemset, but **add one channel** at the input layer:\n",
    "\n",
    "| layer   | input_size  | output_size | filter_size  | stride | n_filters |activation| var sizes  | params |\n",
    "| ------- |:-----------:|:-----------:|:------------:|:------:|:---------:|:--------:|:--------------:| |\n",
    "| conv1, **EXTRA CHANNEL**   | 32x32x**<big>4</big>**     | 32x32x9     | 5x5          |1       | 15        | relu     | W1 = [5,5,**<big>4</big>**,15]<br/> b = [15]||\n",
    "| conv2   | 32x32x15    | 16x16x18    | 5x5          |2       | 18        | relu     | W2 = [5,5,15,18]<br/> b = [18]||\n",
    "| conv3   | 16x16x18    | 8x8x20      | 3x3          |2       | 20        | relu     | W2 = [3,3,18,20]<br/> b =[20]||\n",
    "| maxpool | 8x8x20      | 4x4x20      |              |        |           |          | | k = 2 |\n",
    "| fc      | 4x4x20      |    100      |              |        |           | relu     | W3 = [320,100] <br/>b=[100]||\n",
    "| dropout | 100         |   100       |              |        |           |          | | pkeep = .75 |\n",
    "| output  | 100         |   10        |              |        |           | softmax  | W4 = [100,10] <br/>b=[10]||\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    tf.reset_default_graph()\n",
    "    num_classes=10\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    network = ...\n",
    "    model   = ...\n",
    "    return model\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "vars = {i.name:i for i in tflearn.variables.get_all_trainable_variable()}\n",
    "vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn_cifar10_channel\" + datetime.now().strftime(\"%m-%d_%H:%M\")\n",
    "print model_name\n",
    "model = get_model()\n",
    "# --------------------------\n",
    "# YOUR CODE HERE\n",
    "# --------------------------\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: visualize filters, sample misses and activations\n",
    "\n",
    "for **filters on the first layer** make two visualizations. one for the first **3 channels** and one for the additional channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# YOUR CODE HERE\n",
    "# --------------------------\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

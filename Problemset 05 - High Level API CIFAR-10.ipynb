{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from rlx.ml import Batches, show_image_mosaic\n",
    "from rlx.utils import humanbytes\n",
    "from time import time\n",
    "import tflearn, psutil, gc\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Get CIFAR-10\n",
    "\n",
    "download the dataset from https://www.cs.toronto.edu/~kriz/cifar.html and create a function to return selected batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar(batches = [1,2,3,4,5]):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "    \n",
    "    return imgs, labels, ohlabs\n",
    "\n",
    "def train_test_split(imgs, labels, ohlabs, train_pct=.8, shuffle=True):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "\n",
    "    return train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now create the TEST/TRAIN split. ** we will use only batch 1  ** and select randomly **80%** for **TRAIN** and the rest for **TEST**\n",
    "\n",
    "variables names and shapes must be as follows:\n",
    "\n",
    "\n",
    "        VARIABLE NAME   SHAPE\n",
    "        \n",
    "        imgs            (10000, 32, 32, 3)\n",
    "        labels          (10000,)\n",
    "        onehot          (10000, 10)\n",
    "\n",
    "        train_imgs      (8000, 32, 32, 3)\n",
    "        train_labels    (8000,)\n",
    "        train_ohlabs    (8000, 10)\n",
    "\n",
    "        test_imgs       (2000, 32, 32, 3)\n",
    "        test_labels     (2000,)\n",
    "        test_ohlabs     (2000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels, ohlabs = load_cifar(batches = [1])\n",
    "d = train_test_split(imgs, labels, ohlabs)\n",
    "train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs = d\n",
    "\n",
    "cnames = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"boat\", \"truck\"]\n",
    "\n",
    "print \"imgs  \", imgs.shape, \"min\", np.min(imgs), \"max\", np.max(imgs)\n",
    "print \"labels\", labels.shape\n",
    "print \"onehot\", ohlabs.shape\n",
    "print \"train_imgs  \", train_imgs.shape\n",
    "print \"train_labels\", train_labels.shape\n",
    "print \"train_ohlabs\", train_ohlabs.shape\n",
    "print \"test_imgs   \", test_imgs.shape\n",
    "print \"test_labels \", test_labels.shape\n",
    "print \"test_ohlabs \", test_ohlabs.shape\n",
    "gc.collect()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_mosaic(train_imgs, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Build `tflearn` model\n",
    "\n",
    "use the same network as in the previous problemset:\n",
    "\n",
    "| layer   | input_size  | output_size | filter_size  | stride | n_filters |activation| var sizes  | params |\n",
    "| ------- |:-----------:|:-----------:|:------------:|:------:|:---------:|:--------:|:--------------:| |\n",
    "| conv1   | 32x32x3     | 32x32x9     | 5x5          |1       | 15        | relu     | W1 = [5,5,3,15]<br/> b = [15]||\n",
    "| conv2   | 32x32x15    | 16x16x18    | 5x5          |2       | 18        | relu     | W2 = [5,5,15,18]<br/> b = [18]||\n",
    "| conv3   | 16x16x18    | 8x8x20      | 3x3          |2       | 20        | relu     | W2 = [3,3,18,20]<br/> b =[20]||\n",
    "| maxpool | 8x8x20      | 4x4x20      |              |        |           |          | | k = 2 |\n",
    "| fc      | 4x4x20      |    100      |              |        |           | relu     | W3 = [320,100] <br/>b=[100]||\n",
    "| dropout | 100         |   100       |              |        |           |          | | pkeep = .75 |\n",
    "| output  | 100         |   10        |              |        |           | softmax  | W4 = [100,10] <br/>b=[10]||\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    tf.reset_default_graph()\n",
    "    num_classes=10\n",
    "\n",
    "    network = ...\n",
    "\n",
    "    model   = ...\n",
    "    \n",
    "    return model\n",
    "gc.collect()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check variables are defined correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "vars = {i.name:i for i in tflearn.variables.get_all_trainable_variable()}\n",
    "vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete the call to `fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model_name = \"tflearn_cnn_cifar10_\" + datetime.now().strftime(\"%m-%d_%H:%M\")\n",
    "\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: show confusion matrix (test), misses, filters and sample activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show confussion matrix for test imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show first layer filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show some misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show conv1 activations for a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

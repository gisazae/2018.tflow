{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from rlx.ml import Batches, show_image_mosaic\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "from rlx.utils import humanbytes\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: load weights for first convolutional layer as trained with ImageNet\n",
    "\n",
    "get the pretrained weights for alexnet from https://www.cs.toronto.edu/~guerzhoy/tf_alexnet/\n",
    "\n",
    "you should get weights such as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='imgs/alexnet_filters1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alexnet_weights():\n",
    "    # ---------------------\n",
    "    # YOUR CODE HERE\n",
    "    w = ...\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = get_alexnet_weights()\n",
    "\n",
    "print w.keys()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)\n",
    "\n",
    "conv1_w = w[\"conv1\"][0]\n",
    "conv1_b = w[\"conv1\"][1]\n",
    "conv2_w = w[\"conv2\"][0]\n",
    "conv2_b = w[\"conv2\"][1]\n",
    "conv3_w = w[\"conv3\"][0]\n",
    "conv3_b = w[\"conv3\"][1]\n",
    "print conv1_w.shape, conv1_b.shape\n",
    "print conv2_w.shape, conv2_b.shape\n",
    "print conv3_w.shape, conv3_b.shape\n",
    "\n",
    "conv2_w = np.concatenate((conv2_w,conv2_w),axis=2)\n",
    "print conv2_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imgs(w, figsize=(6,6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    w = (w-np.min(w))/(np.max(w)-np.min(w))\n",
    "    for i in range(w.shape[-1]):\n",
    "        plt.subplot(10,10,i+1)\n",
    "        plt.imshow(w[:,:,:,i], interpolation=\"none\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "display_imgs(conv1_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Load CIFAR-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar(batches = [1,2,3,4,5]):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "    \n",
    "    return imgs, labels, ohlabs\n",
    "\n",
    "def train_test_split(imgs, labels, ohlabs, train_pct=.8, shuffle=True):\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    ...\n",
    "\n",
    "    return train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels, ohlabs = load_cifar(batches = [1])\n",
    "d = train_test_split(imgs, labels, ohlabs)\n",
    "train_imgs, train_labels, train_ohlabs, test_imgs, test_labels, test_ohlabs = d\n",
    "\n",
    "cnames = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"boat\", \"truck\"]\n",
    "\n",
    "print \"imgs  \", imgs.shape, \"min\", np.min(imgs), \"max\", np.max(imgs)\n",
    "print \"labels\", labels.shape\n",
    "print \"onehot\", ohlabs.shape\n",
    "print \"train_imgs  \", train_imgs.shape\n",
    "print \"train_labels\", train_labels.shape\n",
    "print \"train_ohlabs\", train_ohlabs.shape\n",
    "print \"test_imgs   \", test_imgs.shape\n",
    "print \"test_labels \", test_labels.shape\n",
    "print \"test_ohlabs \", test_ohlabs.shape\n",
    "gc.collect()\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_mosaic(train_imgs, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Build `tflearn` model\n",
    "\n",
    "use the same network as in the previous problemset:\n",
    "\n",
    "| layer   | input_size  | output_size | filter_size  | stride | n_filters |activation| var sizes  | params |\n",
    "| ------- |:-----------:|:-----------:|:------------:|:------:|:---------:|:--------:|:--------------:| |\n",
    "| conv1   | 32x32x3     | 32x32x9     | 5x5          |1       | 15        | relu     | W1 = [5,5,3,15]<br/> b = [15]||\n",
    "| conv2   | 32x32x15    | 16x16x18    | 5x5          |2       | 18        | relu     | W2 = [5,5,15,18]<br/> b = [18]||\n",
    "| conv3   | 16x16x18    | 8x8x20      | 3x3          |2       | 20        | relu     | W2 = [3,3,18,20]<br/> b =[20]||\n",
    "| maxpool | 8x8x20      | 4x4x20      |              |        |           |          | | k = 2 |\n",
    "| fc      | 4x4x20      |    100      |              |        |           | relu     | W3 = [320,100] <br/>b=[100]||\n",
    "| dropout | 100         |   100       |              |        |           |          | | pkeep = .75 |\n",
    "| output  | 100         |   10        |              |        |           | softmax  | W4 = [100,10] <br/>b=[10]||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    tf.reset_default_graph()\n",
    "    num_classes=10\n",
    "    \n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    network = ...\n",
    "    model   = ...\n",
    "    \n",
    "    return model\n",
    "print \"free mem\", humanbytes(psutil.virtual_memory().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: scale Alexnet weights for the first  layer\n",
    "\n",
    "use [`skimage.transform.resize`](http://scikit-image.org/docs/dev/api/skimage.transform.html?highlight=resize#skimage.transform.resize). Weights in  `conv1` need to be transformed from  `[11,11,3,96]` to `[5,5,3,96]` by resizing **EACH** filter. Weights in `conv2` **DO NOT** need to be resized. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_conv1_weights(w):\n",
    "    from skimage.transform import resize\n",
    "    conv1_ws = np.zeros([5,5,3,96])\n",
    "    \n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    \n",
    "    return conv1_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = get_alexnet_weights()\n",
    "conv1_ws = scale_conv1_weights(w)\n",
    "print conv1_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_imgs(conv1_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: select random filters two first AlexNet layers and set weights in your model\n",
    "\n",
    "- for layer 1 need to select filters so that [5,5,3,96] becomes [5,5,3,15]\n",
    "- for layer 2 need to select filters so that [5,5,48,256] becomes [5,5,15,18] $\\rightarrow$ **NEED TO SELECT THE FILTERS IN L2 CORRESPONDING TO THOSE SELECTED IN L1**. If filter number `i` is selected in the first layer, then you must choose between filters in `[:,:,i/2,:]` in layer 2. we use `i/2` assuming layer's 2 correct size is `[5,5,96,256]` by collating a copy of `[5,5,48.256]` with itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: select random filters from AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_filters(n_filters_layer_1, n_filters_layer_2):\n",
    "    w        = get_alexnet_weights()\n",
    "    conv1_ws = scale_conv1_weights(w)\n",
    "    \n",
    "    conv1_b  = w[\"conv1\"][1]\n",
    "    conv2_w  = w[\"conv2\"][0]\n",
    "    conv2_b  = w[\"conv2\"][1]\n",
    "    \n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    selected_conv1_ws = ...\n",
    "    selected_conv1_b  = ...\n",
    "\n",
    "    selected_conv2_w  = ...\n",
    "    selected_conv2_b  = ...\n",
    "\n",
    "    return selected_conv1_ws, selected_conv1_b, selected_conv2_w, selected_conv2_b\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check your code. observe how we use `tflearn.variables.get_all_trainable_variable()` to get all TF variables and discover the number of filters for the first two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "vars = {i.name:i for i in tflearn.variables.get_all_trainable_variable()}\n",
    "n_filters_layer_1 = vars[\"conv1/W:0\"].shape.as_list()[-1]\n",
    "n_filters_layer_2 = vars[\"conv2/W:0\"].shape.as_list()[-1]\n",
    "print \"filters in conv1:\", n_filters_layer_1\n",
    "print \"filters in conv2:\", n_filters_layer_2\n",
    "\n",
    "r = select_filters(n_filters_layer_1, n_filters_layer_2)\n",
    "selected_conv1_ws, selected_conv1_b, selected_conv2_w, selected_conv2_b = r\n",
    "\n",
    "print \"conv1 shapes:\", selected_conv1_ws.shape, selected_conv1_b.shape\n",
    "print \"conv2 shapes:\", selected_conv2_w.shape, selected_conv2_b.shape\n",
    "\n",
    "display_imgs(selected_conv1_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: set weights in filters from selected filters\n",
    "\n",
    "user `model.set_weights` and the `vars` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_conv1_conv2_weights(model, selected_conv1_ws, selected_conv1_b, selected_conv2_w, selected_conv2_b):\n",
    "    \n",
    "    vars = {i.name:i for i in tflearn.variables.get_all_trainable_variable()}\n",
    "\n",
    "    # --------------------------\n",
    "    # YOUR CODE HERE\n",
    "    # --------------------------\n",
    "    model.set_weights( ... ) # for conv1/W:0\n",
    "    model.set_weights( ... ) # for conv1/b:0\n",
    "    model.set_weights( ... ) # for conv2/W:0\n",
    "    model.set_weights( ... ) # for conv2/b:0\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model = set_conv1_conv2_weights(model, selected_conv1_ws, selected_conv1_b, selected_conv2_w, selected_conv2_b)\n",
    "\n",
    "vars = {i.name:i for i in tflearn.variables.get_all_trainable_variable()}\n",
    "\n",
    "print \"check conv1/W\", np.allclose(model.get_weights(vars[\"conv1/W:0\"]), selected_conv1_ws)\n",
    "print \"check conv1/b\", np.allclose(model.get_weights(vars[\"conv1/b:0\"]), selected_conv1_b)\n",
    "print \"check conv2/W\", np.allclose(model.get_weights(vars[\"conv2/W:0\"]), selected_conv2_w)\n",
    "print \"check conv2/b\", np.allclose(model.get_weights(vars[\"conv2/b:0\"]), selected_conv2_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: train model\n",
    "\n",
    "if lucky in filter selection model will train faster!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "r = select_filters(n_filters_layer_1, n_filters_layer_2)\n",
    "selected_conv1_ws, selected_conv1_b, selected_conv2_w, selected_conv2_b = r\n",
    "\n",
    "model = set_conv1_conv2_weights(model, selected_conv1_ws, selected_conv1_b, selected_conv2_w, selected_conv2_b)\n",
    "\n",
    "model_name = \"alexnet_cifar10_\" + datetime.now().strftime(\"%m-%d_%H:%M\")\n",
    "print model_name\n",
    "\n",
    "# --------------------------\n",
    "# YOUR CODE HERE\n",
    "# --------------------------\n",
    "model.fit(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weights in layer 1 must have changed very little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = model.get_weights(vars[\"conv1/W:0\"])\n",
    "display_imgs(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_imgs(selected_conv1_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
